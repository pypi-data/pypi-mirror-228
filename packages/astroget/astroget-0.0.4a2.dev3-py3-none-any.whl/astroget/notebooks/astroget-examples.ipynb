{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ASTROGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "__author__ = 'Steve Pothier <steve.pothier@noirlab.edu>'\n",
    "__version__ = '20230831' # yyyymmdd; \n",
    "__keywords__ = ['HowTo', 'astronomy', 'tutorial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This notebook demonstrates using the `astroget` package to get metadata and pixel data from the [NOIRLab Astro Data Archive](https://astroarchive.noirlab.edu/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Table of contents\n",
    "* [Goals & Summary](#goalssummary)\n",
    "* [Imports and setup](#imports)\n",
    "* [Discover Images](#discover)\n",
    "* [Get HDU](#gethdu)\n",
    "* [Get cutout of object](#cutout)\n",
    "* [Generate photo album](#album)\n",
    "* [Find all Messier objects](#messier)\n",
    "* [Save Messier snapshots](#save_album)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"goals\"></a>\n",
    "## Goals & Summary \n",
    "Demonstrate the use of the `astroget` package to get metadata and pixel data from the [NOIRLab Astro Data Archive](https://astroarchive.noirlab.edu/). \n",
    "- Discovery: Search for matching metadata and return metadata records.\n",
    "- Find images containing regions of sky (SIA)\n",
    "- Retrieve images\n",
    "  + Full FITS file\n",
    "  + Single HDU of FITS file\n",
    "  + Cutout of rectangular region of one HDU of a FITS file (as a new FITS file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"imports\"></a>\n",
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pformat as pf\n",
    "import os.path\n",
    "from importlib import reload\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass\n",
    "\n",
    "# Suppress astropy warnings such as:\n",
    "# WARNING: The following header keyword is invalid or follows an unrecognized ...\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "warnings.simplefilter('ignore', category=AstropyWarning)\n",
    "\n",
    "# %matplotlib inline\n",
    "# requires installing ipympl\n",
    "%matplotlib widget\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"install\"></a>\n",
    "## Install the most recent version of the `astroget`:\n",
    "*NOTE: After installing the most recent version, please restart your kernel.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting astroget==0.0.4a2.dev2\n",
      "  Downloading astroget-0.0.4a2.dev2-py3-none-any.whl (219 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: astroget\n",
      "  Attempting uninstall: astroget\n",
      "    Found existing installation: astroget 0.0.3\n",
      "    Uninstalling astroget-0.0.3:\n",
      "      Successfully uninstalled astroget-0.0.3\n",
      "Successfully installed astroget-0.0.4a2.dev2\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pyproject.toml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!pip install -U astroget\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#!pip install astroget==0.0.4a1.dev1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install astroget==0.0.4a2.dev2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mastroget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mastroget\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tic,toc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/astroget/__init__.py:35\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# See semantic versioning\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# BUT PyPi requires honoring versions like this:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#   It will miss the current local copy\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#__version__ = importlib.metadata.version(\"astroget\") # __package__ or __name__\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtoml\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[43mtoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyproject.toml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/toml/decoder.py:133\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, _dict, decoder)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m\"\"\"Parses named file or files as toml and returns a dictionary\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    (Python 2 / Python 3)          file paths is passed\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _ispath(f):\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_getpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ffile:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m loads(ffile\u001b[38;5;241m.\u001b[39mread(), _dict, decoder)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pyproject.toml'"
     ]
    }
   ],
   "source": [
    "#!pip install -U astroget\n",
    "#!pip install astroget==0.0.4a1.dev1\n",
    "!pip install astroget==0.0.4a2.dev3\n",
    "import astroget.client\n",
    "from astroget.utils import tic,toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(astroget.client)\n",
    "print(f'Run started: {str(datetime.now())}')\n",
    "# Server used must support client.cutout() method !!!\n",
    "#server='https://astroarchive.noirlab.edu'     # Public server, HDUs>=408,118,252 Files>=18,731,991\n",
    "server='https://marsnat1-pat.csdc.noirlab.edu' # Test Server,   HDUs>=26,246,808  Files>=711,608\n",
    "#server='http://localhost:8060'                # Dev Server,    HDUs>=1,216\n",
    "client = astroget.client.CsdcClient(url=server, show_curl=True)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic Use of `astroget` for Cutouts\n",
    "- Discover list of HDUs that contain pixels we want\n",
    "  + get/display some metadata in pandas\n",
    "  + retrieve/display a full matching HDU\n",
    "- Cutout from HDU and display\n",
    "- Cutout subimages from multiple HDUs and save FITS (appropriately named)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"discover\"></a>\n",
    "## Find image/HDU of an object\n",
    "Get position from name. Use additional constraints on the FITS files selected.\n",
    "Display one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each HDU record contains `ra` and `dec` fields. Each of those is a RANGE. The Target for our cutout is given by an RA/DEC center and a size.  We can construct RA and DEC ranges for the Target (RA +/- width, DEC +/- height) We want only the HDUs that completely contain the Target. This kind of query can be done against our PostgreSQL 13 database using a \"@>\" (\"contains\") range operator.\n",
    "\n",
    "   E.G. *ra @> target_ra*\n",
    "\n",
    "Unfortunately, the syntax in FIND does not current support this. Fortunately, VOHDU does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Discover image(s) of object using VOHDU\n",
    "#fname='/net/archive/pipe/20170803/ct4m/2017B-0951/c4d_170804_050615_oow_r_v1.fits.fz'\n",
    "#obj_name = 'M65' #65,(77,96)\n",
    "obj_name = 'M54'  # ingested into DEV\n",
    "obj_coord = SkyCoord.from_name(obj_name)\n",
    "ra = obj_coord.ra.degree\n",
    "dec = obj_coord.dec.degree\n",
    "\n",
    "# default search using Overlap (essentially Postgres \"&&\" range operator)\n",
    "# Use very small size to approximate \"obj center in HDU\"\n",
    "#search_size = 0.0001 # radius in degrees\n",
    "search_size = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We will search {client.find(count=True,filerec=False).records[0][\"count\"]:,} HDUs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prod_type=image\n",
    "# proc_type=stack,stacked\n",
    "found = client.vohdu((ra,dec), search_size,  # position=(ra,dec), size(in decimal degrees)\n",
    "            instrument='decam', obs_type='object', proc_type='instcal',\n",
    "            VERB=3, limit=None, verbose=False)\n",
    "\n",
    "assert found.count > 0, 'Must have some objects to use CUTOUT'\n",
    "print(f'Found {found.count} matches of object {obj_name} at position: ra,dec={(ra,dec)} using client.vohdu()')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdus = [[rec[k] for k in ['md5sum','hdu_idx']] for rec in found.records]\n",
    "targets = [[fid, hdu, ra, dec] for (fid,hdu) in hdus]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "recidx = 0\n",
    "rec = found.records[recidx]\n",
    "print(f'Show 1 of {found.count} records. rec[{recidx}] = ')\n",
    "print(f'{pf(rec)}')\n",
    "\n",
    "md5 = rec['md5sum']\n",
    "hduidx = rec['hdu_idx']\n",
    "hduurl = rec['url']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API needs improvement; DISABLED\n",
    "For FIND to be adequate for our needs, we need to be able to do something like:\n",
    "\n",
    "`client.find(outfileds=[...], constraints={'hdu:ra': [target_ra, 'contains']})`\n",
    "\n",
    "where 'ra' refers to the HDU RA field (defined as a range) and 'target_ra' refers to the range of RA we want in our cutout meaning numrange(min_target_ra, max_target_ra)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Discover image(s) of object using FIND; Not adequate!!!\n",
    "obj_name = 'M54'  # ingested into DEV\n",
    "obj_coord = SkyCoord.from_name(obj_name)\n",
    "ra1 = obj_coord.ra.degree\n",
    "dec1 = obj_coord.dec.degree\n",
    "\n",
    "found = client.find(outfields=['archive_filename',\n",
    "                               'md5sum', 'hdu:hdu_idx', 'hdu:ra_center', 'hdu:dec_center'],\n",
    "                    constraints={\n",
    "                        #!'archive_filename': ['m54', 'contains'],\n",
    "                        #!'hdu:ra_min': [ra1 - 0.5, ra1 + 0.5], # Cannot resolve keyword 'ra_min' into field.\n",
    "                        'instrument': ['decam'], \n",
    "                        'obs_type': ['object'], \n",
    "                        'proc_type': ['instcal']\n",
    "                    },\n",
    "                    limit=None, \n",
    "                    verbose=False\n",
    "                    )\n",
    "print(f'Found {found.count} records')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "found.records[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"gethdu\"></a>\n",
    "## Get and Display one HDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure archive file is valid.  Normally this will always be true, but we \n",
    "# are recovering from a \"mass storage\" outage.\n",
    "assert client.fitscheck(md5)['valid'], f\"Invalid FITS file {rec['archive_filename']}\"\n",
    "\n",
    "# Image might be prioprietary. If so, using api/retrieve URL will error. \n",
    "# (But its possible to provide credentials...)\n",
    "# API should provide more helpful error messages for exceptions: timeout, proprietary !!!\n",
    "header0 = fits.getheader(hduurl, 0) # hdu0=Primary, hdu1=image\n",
    "image_data1, header1 = fits.getdata(hduurl, 1, header=True) # hdu0=Primary, hdu1=image\n",
    "print(f'HDU size in pixels = {image_data1.shape}')\n",
    "\n",
    "%matplotlib widget\n",
    "plt.imshow(image_data1, origin='lower', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"cutout\"></a>\n",
    "## Cutout subimage from HDU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#subimage_size = 800\n",
    "subimage_size = 150\n",
    "print(f'Get subimage centered at ra,dec={(ra,dec)} size {subimage_size}. From image md5,hduidx=({md5}, {hduidx})')\n",
    "# get FITS file\n",
    "subimage = client.cutout(ra, dec, subimage_size, md5, hduidx, verbose=True)\n",
    "print(f'subimage as been cutout into local FITS file: {subimage}')\n",
    "\n",
    "image_data = fits.getdata(subimage)\n",
    "plt.figure()\n",
    "plt.imshow(image_data, origin='lower', cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cutouts\"></a>\n",
    "# Get a BATCH of cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stopping execution to avoid long running search. \"\n",
    "      \"Continue manually if you want.\")\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"discoverBatch\"></a>\n",
    "## Find image/HDU of an object\n",
    "Get position from name. Use additional constraints on the FITS files selected."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Discover images of object using VOHDU\n",
    "obj_name = 'M54'  # ingested into DEV\n",
    "obj_coord = SkyCoord.from_name(obj_name)\n",
    "ra = obj_coord.ra.degree\n",
    "dec = obj_coord.dec.degree\n",
    "\n",
    "search_size = 0.05\n",
    "\n",
    "# prod_type=image\n",
    "# proc_type=stack,stacked\n",
    "found = client.vohdu((ra,dec), search_size,  # position=(ra,dec), size(in decimal degrees)\n",
    "            instrument='decam', obs_type='object', proc_type='instcal',\n",
    "            VERB=3, limit=None, verbose=False)\n",
    "\n",
    "print(f'Found {found.count} matches of object {obj_name} at position: ra,dec={(ra,dec)} using client.vohdu()')\n",
    "assert found.count > 0, 'Must have some objects to use CUTOUT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = client.cutouts(150, targets, wait=True, verbose=True)\n",
    "print(f'Cutouts are available for download from {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "recidx = 0\n",
    "rec = found.records[recidx]\n",
    "print(f'Show 1 of {found.count} records. rec[{recidx}] = ')\n",
    "print(f'{pf(rec)}')\n",
    "\n",
    "md5 = rec['md5sum']\n",
    "hduidx = rec['hdu_idx']\n",
    "hduurl = rec['url']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some fields of all records\n",
    "mykeys = {'archive_filename', 'md5sum', 'hdu_idx'}\n",
    "[{k: rec[k] for k in mykeys} for rec in found.records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: two HDUs match in m54-6.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cutoutBatch\"></a>\n",
    "## Cutout a batch of subimages corresponding to many HDUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subimage_size = 150\n",
    "print(f'Get subimage centered at ra,dec={(ra,dec)} size {subimage_size}'\n",
    "      f' from image many HDUs')\n",
    "# get tarball of FITS files\n",
    "targets = [[rec['md5sum'], rec['hdu_idx'], ra, dec] for rec in found.records]\n",
    "url = client.cutouts(subimage_size, targets, wait=True, verbose=True)\n",
    "print(f'Cutouts are available for download from {url}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"album\"></a>\n",
    "# Generate astronomy photo album\n",
    "Given a list of astro objects, find images that contain them and extract a subimage of the object. We don't know how big the objects are so all subimages are the same size. That size might be too big or too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stopping execution to avoid long running loop. \"\n",
    "      \"Continue manually if you want.\")\n",
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a class=\"anchor\" id=\"messier\"></a>\n",
    "## Find All Images (HDUs)for Messier objects in the Astro Data Archive\n",
    "For each object name: get its position and search full archive for HDUs that overlap a box around the object position. All 393 mil(26 mil) HDUs are searched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "albumdir = os.path.expanduser('~/astro-album/')\n",
    "search_size = 0.0001 # radius in degrees\n",
    "subimage_size = 800 # square pixels\n",
    "\n",
    "objs = defaultdict(list)\n",
    "for n in range(1,110+1):\n",
    "    name = f'M{n}'\n",
    "    obj_coord = SkyCoord.from_name(name)\n",
    "    ra = obj_coord.ra.degree\n",
    "    dec = obj_coord.dec.degree\n",
    "    \n",
    "    found = client.vohdu((ra,dec), search_size, VERB=3, \n",
    "                        instrument='decam', obs_type='object', proc_type='instcal',\n",
    "                        limit=None)\n",
    "    print(f'Found {found.count} \"{name}\" objects',end='. ')\n",
    "    print\n",
    "    for rec in found.records:\n",
    "        objs[name].append(rec)\n",
    "files = set([(r['md5sum'],r['archive_filename']) for obrecs in objs.values() for r in obrecs])\n",
    "print(f'\\n\\nFound at least one HDU for objects: {[k for k,v in objs.items() if len(v) > 0]}')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Verify validity of all found files\n",
    "total = len(files)\n",
    "invalid = set()\n",
    "for idx,(m,f) in enumerate(files):\n",
    "    print(f'{idx}/{total}',end=', ')\n",
    "    if not client.fitscheck(m)['valid']:\n",
    "        invalid.add(f)\n",
    "print()\n",
    "newbadfiles = invalid\n",
    "len(newbadfiles), len(files)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(invalid))\n",
    "print(invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badfiles = {'/net/archive/pipe/20130910/ct4m/2012B-0001/c4d_130911_034852_ooi_i_d2.fits.fz',\n",
    " '/net/archive/pipe/20160923/ct4m/2012B-0001/c4d_160924_064533_oow_r_v2.fits.fz',\n",
    " '/net/archive/pipe/20190607/ct4m/2019A-0305/c4d_190608_045632_ooi_g_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20150425/DEC15A/20150407/c4d_150410_033027_ooi_z_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20150617/DEC15A/20150611/c4d_150613_092917_ooi_g_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20150719/DEC15A/20150714/c4d_150715_071229_ood_g_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20150918/REQ13B/HETDEX/c4d_131215_034511_oow_Y_v2.fits.fz',\n",
    " '/net/archive/pipeline/Q20160104/DEC15B/20151229/c4d_151230_063527_ood_i_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20160105/DEC15B/20151229/c4d_151230_053314_ood_r_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20160302/DEC16A/20160225/c4d_160302_022120_oow_g_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20160907/DEC16B/20160831/c4d_160906_034258_oow_VR_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20170111/DEC16B/20170102/c4d_170107_080204_oow_z_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20170111/DEC16B/20170102/c4d_170107_081751_oow_u_v1.fits.fz',\n",
    " '/net/archive/pipeline/Q20170111/DEC16B/20170102/c4d_170108_081653_oow_u_v1.fits.fz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(badfiles), len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"save_album\"></a>\n",
    "## Save local subimages for all Messier objects we found\n",
    "Store all FITS subimates in a single directory using a file name that contains the Messier object name.\n",
    "Each `client.cutout()` call makes a web-service call which: reads the HDU image data and metadata, extracts the cutout into a new tempory FITS file that contains the original Primary HDU and Extension=1 HDU that contains the submage (with WCS), and streams the temporary file in the HTTP response.  The client reads the response and saves it to a local file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "aa = '~/astro-album/'\n",
    "albumdir = os.path.expanduser(aa)\n",
    "count = 0\n",
    "tic()\n",
    "for name,v in objs.items():\n",
    "    total = len(v)\n",
    "    for idx,rec in enumerate(v):\n",
    "        print(f'Create cutout for {name}[{idx}/{total}]', end='...')\n",
    "        \n",
    "        #!if name=='M2' and idx==3:\n",
    "        #!    continue\n",
    "        if rec['archive_filename'] in badfiles:\n",
    "            print('skipped', end='...')\n",
    "            continue\n",
    "\n",
    "        obj_coord = SkyCoord.from_name(name)\n",
    "        ra = obj_coord.ra.degree\n",
    "        dec = obj_coord.dec.degree\n",
    "        outfile = f'{albumdir}/subimage_{name}_{idx}.fits'\n",
    "        try:\n",
    "            client.cutout(ra, dec, subimage_size, \n",
    "                          #rec['url'], \n",
    "                          rec['md5sum'], rec['hdu_idx'],\n",
    "                          outfile=outfile)\n",
    "            count += 1\n",
    "        except Exception as err:\n",
    "            print(f'\\nFailed cutout for {name}[{idx}]; {err}')\n",
    "            continue\n",
    "elapsed = toc()\n",
    "print('All Done!\\n')\n",
    "print(f'Created and retrieved {count} cutouts in {elapsed:0.2f} seconds. ({count/elapsed:0.1f} cutouts/sec)') # 0.4\n",
    "#!print(f'You might want to view all files {aa} in  with QFitsView and turn on \"blink\" to get a slide show.')\n",
    "print(f'\\nYou might want to view all files in {aa} with ds9 (SAOImageDS9) and turn on \"blink\" to get a slide show.'\n",
    "      f'\\n  EXAMPLES: '\n",
    "      f'\\n  ds9 {aa}*.fits -blink'\n",
    "      f'\\n  ds9 {aa}*.fits -blink interval 0.1 -blink  # one frame every 0.1 seconds\\n'\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = '~/astro-album/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ds9 {aa}*.fits -blink interval 0.2 -blink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1
  },
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
