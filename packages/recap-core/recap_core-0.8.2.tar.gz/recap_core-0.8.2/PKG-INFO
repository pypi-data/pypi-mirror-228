Metadata-Version: 2.1
Name: recap-core
Version: 0.8.2
Summary: Read schemas from web service, databases, and schema registries in a standard format
Keywords: avro data data catalog data discovery data engineering data governance data infrastructure data integration data pipelines data quality devops devtools etl infrastructure json schema metadata protobuf
Home-page: https://recap.build
Author-Email: Chris Riccomini <criccomini@apache.org>
License: MIT
Project-URL: Documentation, https://recap.build
Project-URL: Homepage, https://recap.build
Project-URL: Repository, https://github.com/recap-cloud/recap
Requires-Python: <=3.11,>=3.10
Provides-Extra: kafka
Provides-Extra: proto
Provides-Extra: hive
Provides-Extra: bigquery
Provides-Extra: json
Provides-Extra: app
Provides-Extra: all
Requires-Dist: confluent-kafka[schema-registry]>=2.1.1; extra == "kafka"
Requires-Dist: proto-schema-parser>=0.2.0; extra == "proto"
Requires-Dist: pymetastore>=0.2.0; extra == "hive"
Requires-Dist: google-cloud-bigquery>=3.11.3; extra == "bigquery"
Requires-Dist: referencing>=0.30.0; extra == "json"
Requires-Dist: httpx>=0.24.1; extra == "json"
Requires-Dist: fastapi>=0.103.0; extra == "app"
Requires-Dist: pydantic>=2.3.0; extra == "app"
Requires-Dist: pydantic-settings>=2.0.3; extra == "app"
Requires-Dist: typer>=0.9.0; extra == "app"
Requires-Dist: uvicorn>=0.23.2; extra == "app"
Requires-Dist: rich>=13.5.2; extra == "app"
Requires-Dist: python-dotenv>=1.0.0; extra == "app"
Requires-Dist: recap-core[app,bigquery,hive,json,kafka,proto]; extra == "all"
Description-Content-Type: text/markdown

<div align="center">
  <img src="https://github.com/recap-cloud/recap/blob/main/static/recap-logo.png?raw=true" alt="recap"></a>
</div>

## What is Recap?

Recap is a Python library that reads and writes schemas from web services, databases, and schema registries in a standard format.

## Use Cases

* Compare schemas
* Check schema compatibility
* Store schemas in a catalog or registry
* Transpile schemas
* Transform schemas

## Supported Formats

| Format      | Read | Write |
| ----------- | ----------- | ----------- |
| [Avro](https://recap.build/docs/converters/avro/) | ✅ | ✅ |
| [Protobuf](https://recap.build/docs/converters/protobuf/) | ✅ | ✅ |
| [JSON Schema](https://recap.build/docs/converters/json-schema/) | ✅ | ✅ |
| [Snowflake](https://recap.build/docs/readers/snowflake/) | ✅ |  |
| [PostgreSQL](https://recap.build/docs/readers/postgresql/) | ✅ |  |
| [MySQL](https://recap.build/docs/readers/mysql/) | ✅ |  |
| [BigQuery](https://recap.build/docs/readers/bigquery/) | ✅ |  |
| [Confluent Schema Registry](https://recap.build/docs/readers/confluent-schema-registry/) | ✅ |  |
| [Hive Metastore](https://recap.build/docs/readers/hive-metastore/) | ✅ |  |

## Documentation

Recap's documentation is available at [recap.build](https://recap.build).

## Supported Types

Recap borrows types from [Apache Arrow](https://arrow.apache.org/)'s [Schema.fbs](https://github.com/apache/arrow/blob/main/format/Schema.fbs) and [Apache Kafka](https://kafka.apache.org/)'s [Schema.java](https://github.com/apache/kafka/blob/trunk/connect/api/src/main/java/org/apache/kafka/connect/data/Schema.java).

* null
* bool
* int
* float
* string
* bytes
* list
* map
* struct
* enum
* union

## Recap Format

Recap schemas can be stored in YAML, TOML, or JSON formats using [Recap's type spec](https://recap.build/specs/type). Here’s a YAML example:

```yaml
type: struct
fields:
  - name: id
    type: int
    bits: 64
    signed: false
  - name: email
    type: string
    bytes: 255
```

## Usage

Install Recap:

```bash
pip install recap-core
```

Get a Recap schema from a Protobuf schema:

```python
from recap.converters.protobuf import ProtobufConverter

protobuf_schema = """
message Person {
    string name = 1;
}
"""

recap_schema = ProtobufConverter().to_recap(protobuf_schema)
```

Or a Snowflake table:

```python
import snowflake.connector
from recap.readers.snowflake import SnowflakeReader

with snowflake.connector.connect(...) as conn:
  recap_schema = SnowflakeReader(conn).to_recap("TABLE", "PUBLIC", "TESTDB")
```

Or Hive's Metastore:

```python
from pymetastore import HMS
from recap.readers.hive_metastore import HiveMetastoreReader

with HMS.create(...) as conn:
  recap_schema = HiveMetastoreReader(conn).to_recap("testdb", "table")
```

And write the schema as an Avro schema:

```python
from recap.converters.avro import AvroConverter
avro_schema = AvroConverter().from_recap(recap_schema)
```

Or as a Protobuf schema:

```python
from recap.converters.protobuf import ProtobufConverter
protobuf_schema = ProtobufConverter().from_recap(recap_schema)
```

## Warning

Recap is still a little baby application. It's going to wake up crying in the middle of the night. It's going to vomit on the floor once in a while. But if you give it some love and care, it'll be worth it. As time goes on, it'll grow up and be more mature. Bear with it.
