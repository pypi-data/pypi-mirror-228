Metadata-Version: 2.1
Name: langchain-xfyun
Version: 0.0.275b2
Summary: 在LangChain中流畅地使用讯飞星火大模型
Home-page: https://github.com/vsxd/langchain-xfyun
License: MIT
Requires-Python: >=3.8.1,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Provides-Extra: all
Provides-Extra: azure
Provides-Extra: clarifai
Provides-Extra: cohere
Provides-Extra: docarray
Provides-Extra: embeddings
Provides-Extra: extended-testing
Provides-Extra: javascript
Provides-Extra: llms
Provides-Extra: openai
Provides-Extra: qdrant
Provides-Extra: text-helpers
Requires-Dist: O365 (>=2.0.26,<3.0.0) ; extra == "all"
Requires-Dist: PyYAML (>=5.3)
Requires-Dist: SQLAlchemy (>=1.4,<3)
Requires-Dist: aiohttp (>=3.8.3,<4.0.0)
Requires-Dist: aleph-alpha-client (>=2.15.0,<3.0.0) ; extra == "all"
Requires-Dist: amadeus (>=8.1.0) ; extra == "all"
Requires-Dist: amazon-textract-caller (<2) ; extra == "extended-testing"
Requires-Dist: arxiv (>=1.4,<2.0) ; extra == "all"
Requires-Dist: assemblyai (>=0.17.0,<0.18.0) ; extra == "extended-testing"
Requires-Dist: async-timeout (>=4.0.0,<5.0.0) ; python_version < "3.11"
Requires-Dist: atlassian-python-api (>=3.36.0,<4.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: awadb (>=0.3.9,<0.4.0) ; extra == "all"
Requires-Dist: azure-ai-formrecognizer (>=3.2.1,<4.0.0) ; extra == "azure" or extra == "all"
Requires-Dist: azure-ai-vision (>=0.11.1b1,<0.12.0) ; extra == "azure" or extra == "all"
Requires-Dist: azure-cognitiveservices-speech (>=1.28.0,<2.0.0) ; extra == "azure" or extra == "all"
Requires-Dist: azure-core (>=1.26.4,<2.0.0) ; extra == "azure"
Requires-Dist: azure-cosmos (>=4.4.0b1,<5.0.0) ; extra == "azure" or extra == "all"
Requires-Dist: azure-identity (>=1.12.0,<2.0.0) ; extra == "azure" or extra == "all"
Requires-Dist: azure-search-documents (==11.4.0b8) ; extra == "azure"
Requires-Dist: beautifulsoup4 (>=4,<5) ; extra == "all" or extra == "extended-testing"
Requires-Dist: bibtexparser (>=1.4.0,<2.0.0) ; extra == "extended-testing"
Requires-Dist: cassio (>=0.0.7,<0.0.8) ; extra == "extended-testing"
Requires-Dist: chardet (>=5.1.0,<6.0.0) ; extra == "text-helpers" or extra == "extended-testing"
Requires-Dist: clarifai (>=9.1.0) ; extra == "llms" or extra == "clarifai" or extra == "all"
Requires-Dist: clickhouse-connect (>=0.5.14,<0.6.0) ; extra == "all"
Requires-Dist: cohere (>=4,<5) ; extra == "llms" or extra == "cohere" or extra == "all"
Requires-Dist: dataclasses-json (>=0.5.7,<0.6.0)
Requires-Dist: deeplake (>=3.6.8,<4.0.0) ; extra == "all"
Requires-Dist: docarray[hnswlib] (>=0.32.0,<0.33.0) ; extra == "docarray" or extra == "all"
Requires-Dist: duckduckgo-search (>=3.8.3,<4.0.0) ; extra == "all"
Requires-Dist: elasticsearch (>=8,<9) ; extra == "all"
Requires-Dist: esprima (>=4.0.1,<5.0.0) ; extra == "javascript" or extra == "all" or extra == "extended-testing"
Requires-Dist: faiss-cpu (>=1,<2) ; extra == "all" or extra == "extended-testing"
Requires-Dist: feedparser (>=6.0.10,<7.0.0) ; extra == "extended-testing"
Requires-Dist: geopandas (>=0.13.1,<0.14.0) ; extra == "extended-testing"
Requires-Dist: gitpython (>=3.1.32,<4.0.0) ; extra == "extended-testing"
Requires-Dist: google-api-python-client (==2.70.0) ; extra == "all"
Requires-Dist: google-auth (>=2.18.1,<3.0.0) ; extra == "all"
Requires-Dist: google-search-results (>=2,<3) ; extra == "all"
Requires-Dist: gptcache (>=0.1.7) ; extra == "all"
Requires-Dist: gql (>=3.4.1,<4.0.0) ; extra == "extended-testing"
Requires-Dist: html2text (>=2020.1.16,<2021.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: huggingface_hub (>=0,<1) ; extra == "llms" or extra == "all"
Requires-Dist: jinja2 (>=3,<4) ; extra == "all" or extra == "extended-testing"
Requires-Dist: jq (>=1.4.1,<2.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: lancedb (>=0.1,<0.2) ; extra == "all"
Requires-Dist: langkit (>=0.0.6,<0.1.0) ; extra == "all"
Requires-Dist: langsmith (>=0.0.21,<0.1.0)
Requires-Dist: lark (>=1.1.5,<2.0.0) ; extra == "all"
Requires-Dist: libdeeplake (>=0.0.60,<0.0.61) ; extra == "all"
Requires-Dist: librosa (>=0.10.0.post2,<0.11.0) ; extra == "all"
Requires-Dist: lxml (>=4.9.2,<5.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: manifest-ml (>=0.0.1,<0.0.2) ; extra == "llms" or extra == "all"
Requires-Dist: markdownify (>=0.11.6,<0.12.0) ; extra == "extended-testing"
Requires-Dist: marqo (>=1.2.4,<2.0.0) ; extra == "all"
Requires-Dist: momento (>=1.5.0,<2.0.0) ; extra == "all"
Requires-Dist: mwparserfromhell (>=0.6.4,<0.7.0) ; extra == "extended-testing"
Requires-Dist: mwxml (>=0.3.3,<0.4.0) ; extra == "extended-testing"
Requires-Dist: nebula3-python (>=3.4.0,<4.0.0) ; extra == "all"
Requires-Dist: neo4j (>=5.8.1,<6.0.0) ; extra == "all"
Requires-Dist: networkx (>=2.6.3,<3.0.0) ; extra == "all"
Requires-Dist: newspaper3k (>=0.2.8,<0.3.0) ; extra == "extended-testing"
Requires-Dist: nlpcloud (>=1,<2) ; extra == "llms" or extra == "all"
Requires-Dist: nltk (>=3,<4) ; extra == "all"
Requires-Dist: nomic (>=1.0.43,<2.0.0) ; extra == "all"
Requires-Dist: numexpr (>=2.8.4,<3.0.0)
Requires-Dist: numpy (>=1,<2)
Requires-Dist: openai (>=0,<1) ; extra == "llms" or extra == "openai" or extra == "azure" or extra == "all" or extra == "extended-testing" or extra == "extended-testing"
Requires-Dist: openapi-schema-pydantic (>=1.2,<2.0) ; extra == "extended-testing"
Requires-Dist: openlm (>=0.0.5,<0.0.6) ; extra == "llms" or extra == "all"
Requires-Dist: opensearch-py (>=2.0.0,<3.0.0) ; extra == "all"
Requires-Dist: pandas (>=2.0.1,<3.0.0) ; extra == "extended-testing"
Requires-Dist: pdfminer-six (>=20221105,<20221106) ; extra == "all" or extra == "extended-testing"
Requires-Dist: pexpect (>=4.8.0,<5.0.0) ; extra == "all"
Requires-Dist: pgvector (>=0.1.6,<0.2.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: pinecone-client (>=2,<3) ; extra == "all"
Requires-Dist: pinecone-text (>=0.4.2,<0.5.0) ; extra == "all"
Requires-Dist: psychicapi (>=0.8.0,<0.9.0) ; extra == "extended-testing"
Requires-Dist: psycopg2-binary (>=2.9.5,<3.0.0) ; extra == "all"
Requires-Dist: py-trello (>=0.19.0,<0.20.0) ; extra == "extended-testing"
Requires-Dist: pydantic (>=1,<2)
Requires-Dist: pymongo (>=4.3.3,<5.0.0) ; extra == "all"
Requires-Dist: pymupdf (>=1.22.3,<2.0.0) ; extra == "extended-testing"
Requires-Dist: pyowm (>=3.3.0,<4.0.0) ; extra == "all"
Requires-Dist: pypdf (>=3.4.0,<4.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: pypdfium2 (>=4.10.0,<5.0.0) ; extra == "extended-testing"
Requires-Dist: pyspark (>=3.4.0,<4.0.0) ; extra == "extended-testing"
Requires-Dist: pytesseract (>=0.3.10,<0.4.0) ; extra == "all"
Requires-Dist: python-arango (>=7.5.9,<8.0.0) ; extra == "all"
Requires-Dist: pyvespa (>=0.33.0,<0.34.0) ; extra == "all"
Requires-Dist: qdrant-client (>=1.3.1,<2.0.0) ; (python_full_version >= "3.8.1" and python_version < "3.12") and (extra == "qdrant" or extra == "all")
Requires-Dist: rank-bm25 (>=0.2.2,<0.3.0) ; extra == "extended-testing"
Requires-Dist: rapidfuzz (>=3.1.1,<4.0.0) ; extra == "extended-testing"
Requires-Dist: rdflib (>=6.3.2,<7.0.0) ; extra == "all"
Requires-Dist: redis (>=4,<5) ; extra == "all"
Requires-Dist: requests (>=2,<3)
Requires-Dist: requests-toolbelt (>=1.0.0,<2.0.0) ; extra == "all" or extra == "extended-testing"
Requires-Dist: scikit-learn (>=1.2.2,<2.0.0) ; extra == "extended-testing"
Requires-Dist: sentence-transformers (>=2,<3) ; extra == "embeddings" or extra == "all"
Requires-Dist: singlestoredb (>=0.7.1,<0.8.0) ; extra == "all"
Requires-Dist: streamlit (>=1.18.0,<2.0.0) ; (python_full_version >= "3.8.1" and python_full_version != "3.9.7" and python_version < "4.0") and (extra == "extended-testing")
Requires-Dist: sympy (>=1.12,<2.0) ; extra == "extended-testing"
Requires-Dist: telethon (>=1.28.5,<2.0.0) ; extra == "extended-testing"
Requires-Dist: tenacity (>=8.1.0,<9.0.0)
Requires-Dist: tensorflow-text (>=2.11.0,<3.0.0) ; (python_version >= "3.10" and python_version < "3.12") and (extra == "all")
Requires-Dist: tigrisdb (>=1.0.0b6,<2.0.0) ; extra == "all"
Requires-Dist: tiktoken (>=0.3.2,<0.4.0) ; (python_version >= "3.9" and python_version < "4.0") and (extra == "openai" or extra == "all")
Requires-Dist: torch (>=1,<3) ; extra == "llms" or extra == "all"
Requires-Dist: tqdm (>=4.48.0) ; extra == "extended-testing"
Requires-Dist: transformers (>=4,<5) ; extra == "llms" or extra == "all"
Requires-Dist: weaviate-client (>=3,<4) ; extra == "all"
Requires-Dist: websocket-client (>=1.6.1,<2.0.0)
Requires-Dist: wikipedia (>=1,<2) ; extra == "all"
Requires-Dist: wolframalpha (==5.0.0) ; extra == "all"
Requires-Dist: xata (>=1.0.0a7,<2.0.0) ; extra == "extended-testing"
Requires-Dist: xmltodict (>=0.13.0,<0.14.0) ; extra == "extended-testing"
Project-URL: Repository, https://github.com/vsxd/langchain-xfyun
Description-Content-Type: text/markdown

# 🦜️🔗✨ LangChain-xfyun

⚡ 在LangChain中流畅地使用讯飞星火大模型 ⚡

[![Release Notes](https://img.shields.io/github/release/vsxd/langchain-xfyun)](https://github.com/vsxd/langchain-xfyun/releases)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/vsxd/langchain-xfyun)
[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/vsxd/langchain-xfyun)
[![GitHub star chart](https://img.shields.io/github/stars/vsxd/langchain-xfyun?style=social)](https://star-history.com/#vsxd/langchain-xfyun)
[![Open Issues](https://img.shields.io/github/issues-raw/vsxd/langchain-xfyun)](https://github.com/vsxd/langchain-xfyun/issues)


## ⏩ 快速安装

`pip install langchain-xfyun`

## 🤔 这是什么？

大型语言模型（LLM）正在成为一种变革性技术，它使开发人员能够构建以前无法构建的应用程序。然而，孤立地使用这些 LLM 通常不足以创建真正强大的应用程序，只有将它们与其他计算或知识来源相结合，才能发挥真正的威力。

- Fork from [langchain](https://github.com/langchain-ai/langchain)

- 添加了讯飞星火大模型的支持，让你可以在langchain中使用SparkLLM

- [TODO] 修改langchain内置prompt以适应SparkLLM

- 其它关于langchain的信息可以参考 [LangChain's original README.md](https://github.com/vsxd/langchain-xfyun/blob/master/README-langchain.md)

## ❓ 如何使用

```python
from langchain_xfyun.chat_models import ChatSpark
from langchain_xfyun.prompts import ChatPromptTemplate
from langchain_xfyun.chains import LLMChain

llm = ChatSpark(app_id="your_app_id", api_key="your_api_key",
                api_secret="your_api_secret")

prompt = ChatPromptTemplate.from_template(
    "我有一个生产[{product}]商品的公司，请帮我取一个最合适的公司名称。只输出答案本身"
)

chain = LLMChain(llm=llm, prompt=prompt, verbose=True)

product = "魔方"
ans = chain.run(product)
print(ans)
```

- 像以前一样使用chat model，现在你可以使用`ChatSpark`而不是`ChatOpenAI`

- 更详细的内容请参考[langchain 官方文档](https://python.langchain.com/docs/use_cases/question_answering/)

## 💁 Contributing

As an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.

For detailed information on how to contribute, see [here](.github/CONTRIBUTING.md).

