Metadata-Version: 2.1
Name: intelliw-onnx
Version: 1.0.0rc1
Summary: An easy to start Intelligent Workshop Algorithm Framework
Home-page: http://git.yonyou.com/iuapaipaas/intelliw-onnx
Author: yonyou
Author-email: yonyou@yonyou.com
Classifier: Development Status :: 3 - Alpha
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENCE
Requires-Dist: numpy (>=1.20)
Requires-Dist: onnx (>=1.14)
Requires-Dist: onnxruntime (>=1.15)

# 智能工场算法框架ONNX工具包（Intelligent Workshop Algorithm Framework ONNX）

### 参数

```
model_path: [required]  Input path(model file or folder)
model_type: [required]  Input model type(ex: paddle/pytorch)
output:     [required]  Output path(ex: ./output.onnx)

op_set:             Set op_set version(default: 11)
input_shape:        [pytorch/paddle required]  Input shape for pytorch/paddle(ex: [1,3,224,224] or [1,3,224,224]/[1,3,56,56])
model_def_file:      [pytorch/paddle required]  Paddle/pytorch model definition file location(ex: --model_def_file ./cnn.py)
model_class_name:   [pytorch/paddle required]  Paddle/pytorch model class name(ex: --model_class_name CNN)
model_weights_file:  Paddle/pytorch model weights file location(ex: --model_weights_file ./0.99667.pth)
model_input_type:   Paddle/pytorch input type(default float, choice is ['float', 'float32', 'float16', 'uint8', 'int8', 'uint16', 'int16', 'uint32', 'int32', 'uint64', 'int64', 'bool'])
params_file:         Paddle/pytorch params declaration file location(ex: --params_file ./params.py)
output_num:         If output num of pytorch model > 1, you can specify it by --output_num
keep_batch:         For pytorch, if set 1, the tool will keep model batch size(if 0, set it to dynamic(-1))"
dynamic_batch:      If set 1, the tool will convert batch size to -1
simplify:           Simplify the model(0:no simplify;1:do simplify; 2:for dynamic model)
simplify_hw:        When h/w is -1, you can specify h/w as you expected(together with --simplify 2)
force_simplify:     Force simplify the model(0:no simplify;1:do simplify; 2:for dynamic model)
```

其中 `params_file` 格式为

```
params.py

param_dict = {"n": 3}
```

### Pytorch to ONNX

#### 代码

```
from intelliw_onnx.convert import ONNXConvert, ConvertArgs

if __name__ == '__main__':
    args = ConvertArgs(model_path='./model.pt',
                       model_type='pytorch',
                       output='./test_tf_model.onnx',
                       input_shape='[1,3,10,10]',
                       model_def_file="./test_onnx_demo.py",
                       model_class_name="MyModel",
                       params_file="./params.py")
    converter = ONNXConvert(args)
    converter.convert()
```

#### 命令行

```
intelliw-onnx convert --model_path ./model.pt --model_type pytorch --output "./output.onnx" --input_shape '[1,3,10,10]' 
  --model_def_file './test_onnx_demo.py' 
  --model_class_name 'MyModel'  
  --params_file ./params.py
```


  
  

### Paddle to ONNX
#### 代码

1 动态paddle模型 
```
from intelliw_onnx.convert import ONNXConvert, ConvertArgs

if __name__ == '__main__':
    args = ConvertArgs(model_path='./xxx',
                       model_type='paddle',
                       output='./paddle.onnx',
                       input_shape='[1,1,28,28] ',
                       model_def_file="./mnist.py ",
                       model_class_name="LeNet",
                       model_weights_file="./paddle_checkpoint/final.pdparams")
    converter = ONNXConvert(args)
    converter.convert()
```
2 静态paddle模型 
```
from intelliw_onnx.convert import ONNXConvert, ConvertArgs

if __name__ == '__main__':
    args = ConvertArgs(model_path='./xxx',
                       model_type='paddle',
                       output='./paddle.onnx')
    converter = ONNXConvert(args)
    converter.convert()
```


#### 命令行
1 动态paddle模型 
```
intelliw-onnx --model_path ./xxx --model_type paddle 
  --output ./paddle.onnx --model_def_file ./mnist.py 
  --model_class_name LeNet --model_weights_file ./paddle_checkpoint/final.pdparams 
  --input_shape [1,1,28,28] 

or

intelliw-onnx --model_path ./xxx --model_type paddle 
  --output ./paddle.onnx --model_class_name paddle.vision.models.LeNet 
  --model_weights_file ./paddle_checkpoint/final.pdparams --input_shape [1,1,28,28] 
```
2 静态paddle模型 
```
intelliw-onnx --model_path ./paddle_model 
  --model_type paddle --output ./paddle.onnx
```
