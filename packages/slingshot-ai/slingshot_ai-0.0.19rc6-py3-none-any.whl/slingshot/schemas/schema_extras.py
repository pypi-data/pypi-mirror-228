"""
Our autogenerated schemas aren't perfect. This file contains extra classes not generated by the automagic.
We also have classes in schema_overrides.py that shadow genearated classes.
"""
import uuid
from datetime import datetime
from enum import Enum
from typing import Any, Generic, Literal, Optional, Protocol, TypeAlias, TypeVar, Union

from pydantic import BaseModel, ConfigDict, Field, field_validator
from pydantic_core.core_schema import FieldValidationInfo
from typing_extensions import Self

from .generated import schemas as generated_schemas

Hyperparameter = dict[str, Any]

DataT = TypeVar("DataT")


class Response(BaseModel, Generic[DataT]):
    data: Optional[DataT] = None
    error: Optional[generated_schemas.SlingshotLogicalError] = None


class Project(Protocol):
    project_id: str
    display_name: str


class ProjectImpl(BaseModel):
    project_id: str
    display_name: str


class HasRunId(Protocol):
    run_id: str


class HasExecutionEnvironmentSpecId(Protocol):
    execution_environment_spec_id: str


class HasExecutionEnvironmentId(Protocol):
    execution_environment_id: str


class HasAppSpecId(Protocol):
    app_spec_id: str


class HasSourceCodeId(Protocol):
    source_code_id: str
    source_code_name: str


class HasBlobArtifactId(Protocol):
    blob_artifact_id: str


class AppInstanceStatus(str, Enum):
    STOPPED = "STOPPED"
    STARTING = "STARTING"
    READY = "READY"
    ERROR = "ERROR"


class JobStatus(str, Enum):
    NEW = "NEW"
    ACTIVE = "ACTIVE"
    SUCCESS = "SUCCESS"
    CANCELLING = "CANCELLING"
    CANCELLED = "CANCELLED"
    ERROR = "ERROR"


class AuthTokenUnion(BaseModel):
    token: str
    user_id: Optional[str] = None
    service_account_id: Optional[str] = None

    @classmethod
    def from_auth_token(cls, auth_token: generated_schemas.AuthToken) -> Self:
        return cls(token=auth_token.token, user_id=auth_token.user_id, service_account_id=None)

    @classmethod
    def from_service_account_token(cls, service_account_token: generated_schemas.ServiceAccountToken) -> Self:
        return cls(
            token=service_account_token.token, user_id=None, service_account_id=service_account_token.service_account_id
        )

    @property
    def is_service_account(self) -> bool:
        return self.service_account_id is not None

    @property
    def is_user(self) -> bool:
        return self.user_id is not None

    @field_validator("service_account_id")
    def validate_xor(cls, v: str | None, info: FieldValidationInfo) -> str | None:
        if v is None and info.data.get("user_id") is None:
            raise ValueError("Both service_account_id and user_id cannot be None")
        if v is not None and info.data.get("user_id") is not None:
            raise ValueError("Both service_account_id and user_id cannot be set")
        return v


# Note: these are copied from the backend schemas, but should ideally be generated from those.
# TODO: Make these into classes so we can differentiate between them in the type system. This will be used when we
#  handle signed URLs and file uploads
LabelStudioText: TypeAlias = str
LabelStudioFileURL: TypeAlias = str

# TODO: Figure out a way to use these without having to resort to type hacking
LabelStudioInputData = TypeVar("LabelStudioInputData", bound=BaseModel)
LabelStudioOutputData = TypeVar("LabelStudioOutputData", bound=BaseModel)


class Result(BaseModel):
    """
    This is the "Y", i.e. the thing you want to predict.
    """

    result_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="resultId"
    )  # UUID generated by the end-user
    task: Optional[str] = Field(
        None,
        description="The task, for example 'question answering'. Useful when there are multiple results for a single "
        "annotation, e.g. if a single example has multiple questions.",
    )
    task_type: Union[Literal["classification"], str] = Field(
        ...,
        alias="taskType",
        description="The task type, for example classification. This can be one of the Slingshot-defined types or "
        "something custom",
    )
    value: Any = Field(  # TODO: Temporary until we figure out how to type this while making mypy and pydantic happy
        ...,
        description="The content of the annotation result. For example, for classification, this would be a "
        "dictionary of class names to booleans",
    )

    model_config = ConfigDict(extra='allow', populate_by_name=True)


class Annotation(BaseModel):
    annotation_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="annotationId"
    )  # UUID generated by the end-user
    result: list[Result] = Field(..., description="The annotation result")
    created_at: Optional[datetime] = Field(
        default_factory=datetime.utcnow, alias="createdAt", description="When the annotation was created"
    )
    updated_at: Optional[datetime] = Field(
        default_factory=datetime.utcnow, alias="updatedAt", description="When the annotation was last updated"
    )
    annotator: Optional[str] = Field(None, alias="annotator", description="The ID or name of the annotator")

    model_config = ConfigDict(populate_by_name=True)


class Prediction(Annotation):
    model: Optional[str] = Field(None, alias="model", description="The ID or name of the model")

    model_config = ConfigDict(populate_by_name=True)


class Example(BaseModel):
    example_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="exampleId"
    )  # UUID generated by the end-user
    created_at: Optional[datetime] = Field(default_factory=datetime.utcnow, alias="createdAt")
    updated_at: Optional[datetime] = Field(default_factory=datetime.utcnow, alias="updatedAt")
    data: Any  # TODO: Temporary until we figure out how to type this while making mypy and pydantic happy
    annotations: list[Annotation] = Field(default_factory=list)
    predictions: list[Prediction] = Field(default_factory=list)

    model_config = ConfigDict(populate_by_name=True)


class ExampleModification(BaseModel):
    example_id: str = Field(..., alias="exampleId")
    modified_data: Optional[BaseModel] = Field(None, alias="modifiedData")
    new_annotations: list[Annotation] = Field(default_factory=list, alias="newAnnotations")
    new_predictions: list[Prediction] = Field(default_factory=list, alias="newPredictions")

    model_config = ConfigDict(populate_by_name=True)


class Upsert(BaseModel):
    """
    Upserts are used to update the dataset
    """

    upsert_id: Optional[str] = Field(None, alias="upsertId")  # UUID generated by the end-user
    new_examples: list[Example] = Field(default_factory=list, alias="newExamples")
    modified_examples: list[ExampleModification] = Field(default_factory=list, alias="modifiedExamples")
    updated_at: datetime = Field(
        default_factory=datetime.utcnow,
        alias="updatedAt",
        description="The time at which the upsert was created. Defaults to now.",
    )

    model_config = ConfigDict(populate_by_name=True)


class Dataset(BaseModel):
    """
    Dataset is a JSONL of examples
    """

    examples: list[Example]
