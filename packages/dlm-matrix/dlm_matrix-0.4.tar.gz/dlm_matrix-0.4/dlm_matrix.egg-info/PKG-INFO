Metadata-Version: 2.1
Name: dlm-matrix
Version: 0.4
Summary: A Divergent Language Matrix
Home-page: https://github.com/diomandeee/dl_matrix
Author: Mohamed Diomande
Author-email: gdiomande7907@gmail.com
License: MIT
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.6
Description-Content-Type: text/markdown
License-File: LICENSE

# Divergent Language Matrix

## Description
The Divergent Language Matrix is a novel approach designed to analyze and understand the intricate structures and dynamics within digital conversations. This repository contains the code and documentation necessary to implement the Divergent Language Matrix framework, allowing you to explore conversations in a new and comprehensive way.

## Introduction
In the realm of digital communication, understanding conversations goes beyond the surface-level exchange of messages. The Divergent Language Matrix framework recognizes conversations as dynamic systems, governed by evolving production rules that shape their evolution. This approach provides a deeper insight into the complexities of conversations by considering various factors such as semantic content, contextual embeddings, and hierarchical relationships.

## Formulation
Divergent Language Matrix (DLM) is designed to generate a lower-dimensional representation of complex, hierarchical text data, such as conversations. The algorithm preserves both semantic and structural relationships within the data, allowing for more efficient analysis and visualization. 

In the Divergent Language Matrix (DLM) framework, a conversation tree \( T \) is formulated as a directed, acyclic graph where each node corresponds to a message in the conversation. Each message \( t_i \) is mathematically defined by a triplet \( (d_i, s_i, c_i) \), such that:

- \( d_i \) represents the depth of the message \( t_i \) within \( T \). The root message has \( d_i = 0 \), and the depth increases as we traverse down the tree.
- \( s_i \) is the ordinal number that signifies the position of \( t_i \) amongst its siblings at depth \( d_i \).
- \( c_i \) denotes the total count of sibling messages at depth \( d_i \). \( c_i \) is constrained to be non-negative, i.e., \( c_i \geq 0 \).

### Key Processing Stages

1. **Text Preprocessing and Segmentation**:  
   - Each message \( M_{i,j} \) is tokenized and segmented into \( k \) distinct parts: \( P_{i,j} = \{P_{i,j,1}, P_{i,j,2}, \ldots, P_{i,j,k}\} \).
   - Syntactic and semantic relations are maintained among these segmented parts, laying the groundwork for in-depth analysis.

2. **Creating Contextual Embeddings with Sentence Transformers**:  
   - We employ Sentence Transformers to generate high-quality, contextual embeddings for each text to create high-dimensional contextual embeddings \( E(P_{i,j,k}) \) for each part.

### 3. Hierarchical Spatial-Temporal Coordinate Assignment

The assignment of hierarchical spatial-temporal coordinates is a cornerstone in the DLM framework, bridging the gap between high-dimensional textual embeddings and the structured representation of a conversation. It assigns each segment a four-dimensional coordinate \( (x, y, z, t) \), encoding both its place in the conversational hierarchy and its chronological order.

#### 3.1. The Framework for Coordinate Assignment

- **The Coordinate Tuple**: Every segment \( P_{i,j,k} \) within a given conversation \( C_i \) is mapped to a unique coordinate tuple \( (x_{i,j,k}, y_{i,j,k}, z_{i,j,k}, t_{i,j,k}) \).
- **Rooted in Message Metadata**: The values of \( x, y, z \) are computed as functions \( f(d_i, s_i, c_i) \), where \( d_i, s_i, c_i \) are as previously defined. 
- **Chronological Timestamp**: \( t_{i,j,k} \) is defined by the temporal metadata associated with the message, normalized to a suitable scale for analysis.

#### 3.2. Spatial Coordinate Calculations

- **X-Axis (Thread Depth)**: \( x_{i,j,k} \) is directly proportional to \( d_i \), representing the depth of the message in the conversation tree. It captures the level of nesting for each message.
  
  \[ x_{i,j,k} = f_x(d_i) \]
  
- **Y-Axis (Sibling Order)**: \( y_{i,j,k} \) is a function of \( s_i \), signifying the message's ordinal position among siblings.
  
  \[ y_{i,j,k} = f_y(s_i) \]
  
- **Z-Axis (Sibling Density)**: \( z_{i,j,k} \) encapsulates the density of sibling messages at a given depth, calculated as a function of \( c_i \).
  
  \[ z_{i,j,k} = f_z(c_i) \]
  
These functions \( f_x, f_y, f_z \) can be linear or nonlinear mappings based on the specific requirements of the analysis.

#### 3.3. Temporal Coordinate Calculations

- **Timestamp Normalization**: The timestamp \( t \) for each message is normalized into a unit scale ranging from 0 to 1 across the entire conversation.
  
  \[ t_{i,j,k} = \frac{{\text{Timestamp of } P_{i,j,k} - \text{Min Timestamp}}}{{\text{Max Timestamp} - \text{Min Timestamp}}} \]
  
#### 3.4. Final Coordinate Assignment

After calculating these coordinates, each segment \( P_{i,j,k} \) in conversation \( C_i \) will have a unique 4D coordinate \( (x_{i,j,k}, y_{i,j,k}, z_{i,j,k}, t_{i,j,k}) \). These coordinates serve as a comprehensive representation of each segment's position in both the conversational hierarchy and the temporal sequence.

Let's dive into a deeper mathematical formulation based on the provided methods to enhance the Dynamic Message Ordering (DMO) within the Hierarchical Spatial-Temporal Coordinate Assignment framework:

### 4. Dynamic Message Ordering (DMO)

The Dynamic Message Ordering (DMO) system utilizes a Hierarchical Spatial-Temporal Coordinate Assignment methodology to arrange messages in a conversation space. Messages are placed in a hierarchical structure, with the spatial coordinates (x, y) assigned based on the relationship to the parent message, and the temporal coordinate (z) influenced by multiple factors including message similarity, temporal weights, and sibling spacing. In essence, the DMO aims to spatially organize messages in such a way that:

- Similar messages are closer in this space.
- The spatial relationship of messages reflects the temporal relationship among them.
- The hierarchical structure is reflected in the spatial coordinates.

#### 4.1. Spacing Calculation (Method: `calculate_spacing`)

In this part, the spacing \( S \) between siblings based on similarity scores is of utmost importance. Let's redefine the mathematical formulation with more specificity:

- **Variable Definitions:**
  - \( n \) = Number of children, \( n = | \text{children\_ids} | \)
  - \( \text{avg\_similarity} \) = Average of normalized similarity scores, \( \frac{\sum_{i=1}^{n} s_i}{n} \)
  - \( s_i \) = Individual normalized similarity scores

- **Mathematical Representation:**

\[
S(n, \text{avg\_similarity}, \text{method}) = 
\begin{cases}
    0 & \text{if } n \leq 1 \\
    -0.5 \times (n - 1) & \text{if method = "spacing"} \\
    (-0.5 + \text{avg\_similarity}) \times (n - 1) & \text{if method = "both"}
\end{cases}
\]

#### 4.2. Temporal Weights Calculation (Method: `calculate_temporal_weights`)

The matrix of temporal weights is calculated as follows:

- **Variable Definitions:**
  - \( t \) = Vector of timestamps, \( t = [t_1, t_2, ..., t_n] \)
  - \( \Delta T \) = Matrix of pairwise time differences, \( \Delta T_{ij} = | t_i - t_j | \)
  
- **Mathematical Representation:**

\[
W_{ij} = f(\Delta T_{ij})
\]

where \( f(x) \) is a decay function, applied element-wise.

#### 4.3. Time Coordinate Calculation (Method: `calculate_time_coordinate`)

In this part, the focus is to determine a singular time coordinate \( T \) for a message. We base it on its relationship with its siblings:

- **Variable Definitions:**
  - \( t_{\text{message}} \) = Timestamp of the current message
  - \( t_{\text{sibling}_i} \) = Timestamps of siblings
  - \( \Delta t_i = t_{\text{sibling}_i} - t_{\text{message}} \)

- **Mathematical Representation:**

\[
T(t_{\text{message}}, \Delta t) = g(\text{time\_diff})
\]

where \( g(x) \) is another decay function, and \( \text{time\_diff} \) is the time difference between the message and a root message.

#### 4.4. Time Decay Factor (Method: `time_decay_factor`)

The time decay factor \( D \) will amalgamate the impacts of both individual message time and sibling relations:

- **Variable Definitions:**
  - \( \text{avg}(\Delta t) \) = Average time differences between a message and its siblings

- **Mathematical Representation:**

\[
D = g(\text{time\_diff}) \times \text{avg}(\Delta t)
\]

#### 5. Dimensionality Reduction via UMAP (Uniform Manifold Approximation and Projection)

UMAP plays a crucial role in reducing the dimensionality of the complex, high-dimensional message representations to a lower-dimensional space where relationships between messages are maintained.

- **Variable Definitions:**
  - \( E(P_{i,j,k}) \) = Embedding for each message \( i \), where \( j \) and \( k \) may denote specific features or layers in the embedding.
  - \( \mathbf{R} \) = Joint representation vector, \( \mathbf{R} = [E(P_{i,j,k}), x, y, z, t] \)

- **Mathematical Representation:**
  
\[
\mathbf{R}_{\text{reduced}} = \text{UMAP}(\mathbf{R})
\]

Where \(\mathbf{R}_{\text{reduced}}\) is the lower-dimensional representation of the original feature vector \( \mathbf{R} \).

#### 6. Clustering and Final Representation using HDBSCAN

HDBSCAN provides an elegant solution to clustering by identifying clusters of varying shapes and densities, making it apt for this application.

- **Variable Definitions:**
  - \( \mathbf{C} \) = Set of clusters, \( \mathbf{C} = \{ C_1, C_2, \ldots, C_m \} \)
  - \( \mathbf{R}_{\text{reduced}} \) = Lower-dimensional representations obtained from UMAP

- **Mathematical Representation:**

\[
\mathbf{C} = \text{HDBSCAN}(\mathbf{R}_{\text{reduced}})
\]

- **Multi-layered Interpretation:**
  
Messages are now characterized not just by their semantic content but also by their spatial-temporal coordinates. This multi-layered approach allows for a more comprehensive understanding of the conversation's topology and semantic themes.

This enhanced and comprehensive approach for Divergent Language Matrix enables a more accurate, coherent, and interpretable representation of the conversation structure, benefiting both researchers and practitioners in the field.
